{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import io\n",
    "import torch\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import argparse\n",
    "from huggingface_hub import snapshot_download\n",
    "from diffusers.image_processor import VaeImageProcessor\n",
    "\n",
    "# Add CatVTON directory to sys.path\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "catvton_dir = os.path.join(parent_dir, \"CatVTON\")\n",
    "if catvton_dir not in sys.path:\n",
    "    sys.path.insert(0, catvton_dir)\n",
    "\n",
    "from model.cloth_masker import AutoMasker, vis_mask\n",
    "from model.pipeline import CatVTONPipeline\n",
    "from utils import init_weight_dtype, resize_and_crop, resize_and_padding\n",
    "\n",
    "def image_grid(images, rows, cols):\n",
    "    if not images:\n",
    "        return None\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "    max_width, max_height = max(widths), max(heights)\n",
    "    grid_img = Image.new('RGB', (cols * max_width, rows * max_height))\n",
    "    for idx, img in enumerate(images):\n",
    "        row = idx // cols\n",
    "        col = idx % cols\n",
    "        grid_img.paste(img, (col * max_width, row * max_height))\n",
    "    return grid_img\n",
    "\n",
    "# 기본 설정값 (args 대체)\n",
    "class Args:\n",
    "    width = 768\n",
    "    height = 1024\n",
    "    output_dir = \"./output\"\n",
    "\n",
    "args_obj = Args()\n",
    "if not os.path.exists(args_obj.output_dir):\n",
    "    os.makedirs(args_obj.output_dir)\n",
    "\n",
    "# repo_path 설정: attn_ckpt와 AutoMasker에서 사용\n",
    "repo_path = snapshot_download(repo_id=\"zhengchong/CatVTON\")\n",
    "\n",
    "# 파이프라인 인스턴스 생성\n",
    "pipeline = CatVTONPipeline(\n",
    "    base_ckpt=\"booksforcharlie/stable-diffusion-inpainting\",\n",
    "    attn_ckpt=\"zhengchong/CatVTON\",        # 학습된 try-on 모델 체크포인트 경로 (attn_ckpt로 사용)\n",
    "    attn_ckpt_version=\"mix\",\n",
    "    weight_dtype=init_weight_dtype(\"bf16\"),\n",
    "    use_tf32=True,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# AutoMasker 및 mask_processor 설정\n",
    "mask_processor = VaeImageProcessor(\n",
    "    vae_scale_factor=8, \n",
    "    do_normalize=False, \n",
    "    do_binarize=True, \n",
    "    do_convert_grayscale=True\n",
    ")\n",
    "automasker = AutoMasker(\n",
    "    densepose_ckpt=os.path.join(repo_path, \"DensePose\"),\n",
    "    schp_ckpt=os.path.join(repo_path, \"SCHP\"),\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "def run_tryon(person_image_path, cloth_image_path, cloth_type,\n",
    "              num_inference_steps=50, guidance_scale=2.5,\n",
    "              seed=-1, show_type=\"result only\"):\n",
    "    try:\n",
    "        # 이미지 로드\n",
    "        person_img = Image.open(person_image_path).convert(\"RGB\")\n",
    "        cloth_img = Image.open(cloth_image_path).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        print(\"유효하지 않은 이미지 파일입니다.\", e)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # 자동 마스킹 수행\n",
    "        mask = automasker(person_img, cloth_type)['mask']\n",
    "        mask = mask_processor.blur(mask, blur_factor=9)\n",
    "        # Seed 설정\n",
    "        generator = (torch.Generator(device='cuda').manual_seed(seed)\n",
    "                     if seed != -1 else None)\n",
    "        # Inference 호출\n",
    "        result_img = pipeline(\n",
    "            image=person_img,\n",
    "            condition_image=cloth_img,\n",
    "            mask=mask,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            generator=generator\n",
    "        )[0]\n",
    "    except Exception as e:\n",
    "        print(\"이미지 생성 중 오류가 발생했습니다.\", e)\n",
    "        return\n",
    "\n",
    "    # 결과 이미지 저장\n",
    "    date_str = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    folder_path = os.path.join(args_obj.output_dir, date_str[:8])\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    result_save_path = os.path.join(folder_path, date_str[8:] + \".png\")\n",
    "    result_img.save(result_save_path)\n",
    "    print(f\"결과 이미지가 저장되었습니다: {result_save_path}\")\n",
    "\n",
    "    # 선택적으로 결과 이미지를 grid 형태로 생성하여 보여줌\n",
    "    if show_type != \"result only\":\n",
    "        masked_person = vis_mask(person_img, mask)\n",
    "        if show_type == \"input & result\":\n",
    "            condition_width = person_img.size[0] // 2\n",
    "            conditions = image_grid([person_img, cloth_img], 2, 1)\n",
    "        else:\n",
    "            condition_width = person_img.size[0] // 3\n",
    "            conditions = image_grid([person_img, masked_person, cloth_img], 3, 1)\n",
    "        conditions = conditions.resize((condition_width, person_img.size[1]), Image.NEAREST)\n",
    "        new_result_image = Image.new(\"RGB\", (person_img.size[0] + condition_width + 5, person_img.size[1]))\n",
    "        new_result_image.paste(conditions, (0, 0))\n",
    "        new_result_image.paste(result_img, (condition_width + 5, 0))\n",
    "        display(new_result_image)\n",
    "    else:\n",
    "        display(result_img)\n",
    "\n",
    "def parse_arguments():\n",
    "    parser = argparse.ArgumentParser(description=\"Run Try-On Inference\")\n",
    "    parser.add_argument(\"--person\", type=str, required=True, help=\"Path to the person image\")\n",
    "    parser.add_argument(\"--cloth\", type=str, required=True, help=\"Path to the cloth image\")\n",
    "    parser.add_argument(\"--cloth_type\", type=str, required=True, help=\"Type of the cloth\")\n",
    "    parser.add_argument(\"--num_inference_steps\", type=int, default=50, help=\"Number of inference steps\")\n",
    "    parser.add_argument(\"--guidance_scale\", type=float, default=2.5, help=\"Guidance scale\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=-1, help=\"Seed value (-1 for random)\")\n",
    "    parser.add_argument(\"--show_type\", type=str, default=\"result only\",\n",
    "                        choices=[\"result only\", \"input & result\", \"full\"],\n",
    "                        help=\"Display type for output image\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Notebook 환경에서는 argparse.parse_args() 작동에 주의-> sys.argv 재정의 필요할 수 있음.\n",
    "    args = parse_arguments()\n",
    "    run_tryon(\n",
    "        person_image_path=args.person,\n",
    "        cloth_image_path=args.cloth,\n",
    "        cloth_type=args.cloth_type,\n",
    "        num_inference_steps=args.num_inference_steps,\n",
    "        guidance_scale=args.guidance_scale,\n",
    "        seed=args.seed,\n",
    "        show_type=args.show_type\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
