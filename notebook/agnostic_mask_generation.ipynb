{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\Users\\coldbrew\\VTON-project\\data\\dataset\\image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 195/195 [00:02<00:00, 93.67it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, sys\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "project_root_dir = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "dataset_person_folder = os.path.join(project_root_dir, \"data\", \"dataset\", \"image\")\n",
    "dataset_person_upper_mask_folder = os.path.join(project_root_dir, \"data\", \"dataset\", \"image_mask_U\")\n",
    "dataset_person_lower_mask_folder = os.path.join(project_root_dir, \"data\", \"dataset\", \"image_mask_L\")\n",
    "\n",
    "dst_person_with_upper_agnostic_folder = os.path.join(project_root_dir, \"data\", \"dataset\", \"image_with_upper_agnostic\")\n",
    "dst_person_with_lower_agnostic_folder = os.path.join(project_root_dir, \"data\", \"dataset\", \"image_with_lower_agnostic\")\n",
    "\n",
    "# 결과 저장 폴더가 없으면 생성\n",
    "os.makedirs(dst_person_with_upper_agnostic_folder, exist_ok=True)\n",
    "os.makedirs(dst_person_with_lower_agnostic_folder, exist_ok=True)\n",
    "\n",
    "# 사람이미지에 각각 마스크 이미지 넣어서 저장\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 사람 이미지 파일 목록 가져오기 (마스크 이미지와 파일명이 동일하다고 가정)\n",
    "person_files = sorted(os.listdir(dataset_person_folder))\n",
    "\n",
    "for file_name in tqdm(person_files, desc=\"Processing images\"):\n",
    "    # 파일 경로 구성\n",
    "    person_img_path = os.path.join(dataset_person_folder, file_name)\n",
    "    upper_mask_path = os.path.join(dataset_person_upper_mask_folder, file_name)\n",
    "    lower_mask_path = os.path.join(dataset_person_lower_mask_folder, file_name)\n",
    "    \n",
    "    # 이미지 로드 (마스크는 그레이스케일로 로드)\n",
    "    person_img = cv2.imread(person_img_path)\n",
    "    upper_mask = cv2.imread(upper_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    lower_mask = cv2.imread(lower_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if person_img is None:\n",
    "        print(f\"Error loading person image: {file_name}\")\n",
    "        continue\n",
    "    if upper_mask is None:\n",
    "        print(f\"Error loading upper mask image: {file_name}\")\n",
    "        continue\n",
    "    if lower_mask is None:\n",
    "        print(f\"Error loading lower mask image: {file_name}\")\n",
    "        continue\n",
    "\n",
    "    # 상체 마스크 적용: 마스크 영역을 검정색(0)으로 채우기\n",
    "    upper_agnostic_img = person_img.copy()\n",
    "    # binary 마스크라고 가정 (0: 배경, 255: 마스크 영역). 임계값 127을 기준으로 처리합니다.\n",
    "    upper_agnostic_img[upper_mask > 127] = 0\n",
    "\n",
    "    # 하체 마스크 적용: 마스크 영역을 검정색(0)으로 채우기\n",
    "    lower_agnostic_img = person_img.copy()\n",
    "    lower_agnostic_img[lower_mask > 127] = 0\n",
    "\n",
    "    # 결과 저장\n",
    "    cv2.imwrite(os.path.join(dst_person_with_upper_agnostic_folder, file_name), upper_agnostic_img)\n",
    "    cv2.imwrite(os.path.join(dst_person_with_lower_agnostic_folder, file_name), lower_agnostic_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "catvton_dir = os.path.join(parent_dir, \"CatVTON\")\n",
    "if catvton_dir not in sys.path:\n",
    "    sys.path.insert(0, catvton_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/coldbrew/anaconda3/envs/torch_book/lib/python3.9/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/Users/coldbrew/anaconda3/envs/torch_book/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <FB2FD416-6C4D-3621-B677-61F07C02A3C5> /Users/coldbrew/anaconda3/envs/torch_book/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/coldbrew/anaconda3/envs/torch_book/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/coldbrew/anaconda3/envs/torch_book/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/coldbrew/anaconda3/envs/torch_book/lib/libjpeg.9.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/coldbrew/anaconda3/envs/torch_book/lib/libjpeg.9.dylib' (no such file), '/Users/coldbrew/anaconda3/envs/torch_book/lib/libjpeg.9.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/coldbrew/anaconda3/envs/torch_book/lib/libjpeg.9.dylib' (no such file), '/Users/coldbrew/anaconda3/envs/torch_book/lib/python3.9/lib-dynload/../../libjpeg.9.dylib' (no such file), '/Users/coldbrew/anaconda3/envs/torch_book/lib/libjpeg.9.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/coldbrew/anaconda3/envs/torch_book/lib/libjpeg.9.dylib' (no such file), '/Users/coldbrew/anaconda3/envs/torch_book/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3a65cd9545495ebbc6c976d9688483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded to: /Users/coldbrew/.cache/huggingface/hub/models--zhengchong--CatVTON/snapshots/2969fcf85fe62f2036605716f0b56f0b81d01d79\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel downloaded to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# AutoMasker 초기화 (DensePose와 SCHP 사용)\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m automasker \u001b[38;5;241m=\u001b[39m \u001b[43mAutoMasker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdensepose_ckpt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDensePose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschp_ckpt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSCHP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# 이미지 폴더 경로\u001b[39;00m\n\u001b[1;32m     29\u001b[0m images_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_root_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/VTON-project/CatVTON/model/cloth_masker.py:165\u001b[0m, in \u001b[0;36mAutoMasker.__init__\u001b[0;34m(self, densepose_ckpt, schp_ckpt, device)\u001b[0m\n\u001b[1;32m    162\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    163\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdensepose_processor \u001b[38;5;241m=\u001b[39m \u001b[43mDensePose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdensepose_ckpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschp_processor_atr \u001b[38;5;241m=\u001b[39m SCHP(ckpt_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(schp_ckpt, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp-schp-201908301523-atr.pth\u001b[39m\u001b[38;5;124m'\u001b[39m), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschp_processor_lip \u001b[38;5;241m=\u001b[39m SCHP(ckpt_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(schp_ckpt, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp-schp-201908261155-lip.pth\u001b[39m\u001b[38;5;124m'\u001b[39m), device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Documents/VTON-project/CatVTON/model/DensePose/__init__.py:41\u001b[0m, in \u001b[0;36mDensePose.__init__\u001b[0;34m(self, model_path, device)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_config()\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor \u001b[38;5;241m=\u001b[39m \u001b[43mDefaultPredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Documents/VTON-project/CatVTON/detectron2/engine/defaults.py:282\u001b[0m, in \u001b[0;36mDefaultPredictor.__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg):\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mclone()  \u001b[38;5;66;03m# cfg can be modified by model\u001b[39;00m\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cfg\u001b[38;5;241m.\u001b[39mDATASETS\u001b[38;5;241m.\u001b[39mTEST):\n",
      "File \u001b[0;32m~/Documents/VTON-project/CatVTON/detectron2/modeling/meta_arch/build.py:23\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     21\u001b[0m meta_arch \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mMODEL\u001b[38;5;241m.\u001b[39mMETA_ARCHITECTURE\n\u001b[1;32m     22\u001b[0m model \u001b[38;5;241m=\u001b[39m META_ARCH_REGISTRY\u001b[38;5;241m.\u001b[39mget(meta_arch)(cfg)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m _log_api_usage(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodeling.meta_arch.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m meta_arch)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_book/lib/python3.9/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_book/lib/python3.9/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_book/lib/python3.9/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_book/lib/python3.9/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_book/lib/python3.9/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_book/lib/python3.9/site-packages/torch/cuda/__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import snapshot_download\n",
    "from tqdm import tqdm\n",
    "from model.cloth_masker import AutoMasker\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image\n",
    "\n",
    "# 데이터셋 경로 설정 (노트북에서 직접 입력)\n",
    "data_root_path = \"/Users/coldbrew/Documents/VTON-project/dataset\"  # Google Colab에서 사용 예시, 로컬 경로로 변경 가능\n",
    "repo_path = \"zhengchong/CatVTON\"  # CatVTON 모델 레포\n",
    "\n",
    "# GPU 사용 확인 (CUDA 사용 가능 여부)\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# CatVTON 모델 다운로드\n",
    "repo_path = snapshot_download(repo_id=repo_path)\n",
    "print(f\"Model downloaded to: {repo_path}\")\n",
    "\n",
    "# AutoMasker 초기화 (DensePose와 SCHP 사용)\n",
    "automasker = AutoMasker(\n",
    "    densepose_ckpt=os.path.join(repo_path, \"DensePose\"),\n",
    "    schp_ckpt=os.path.join(repo_path, \"SCHP\"),\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# 이미지 폴더 경로\n",
    "images_dir = os.path.join(data_root_path, \"images\")\n",
    "assert os.path.exists(images_dir), f\"Images folder {images_dir} does not exist.\"\n",
    "\n",
    "# 상의 및 하의 마스크를 저장할 출력 디렉토리 생성\n",
    "upper_output_dir = os.path.join(data_root_path, \"upper_agnostic_masks\")\n",
    "lower_output_dir = os.path.join(data_root_path, \"lower_agnostic_masks\")\n",
    "os.makedirs(upper_output_dir, exist_ok=True)\n",
    "os.makedirs(lower_output_dir, exist_ok=True)\n",
    "\n",
    "# images 폴더의 모든 .jpg 파일 처리\n",
    "image_files = [f for f in os.listdir(images_dir) if f.endswith('.jpg')]\n",
    "print(f\"Found {len(image_files)} .jpg files in {images_dir}\")\n",
    "\n",
    "for image_file in tqdm(image_files, desc=\"Processing images\"):\n",
    "    image_path = os.path.join(images_dir, image_file)\n",
    "    \n",
    "    # 상의 마스크 생성 및 저장\n",
    "    upper_mask = automasker(\n",
    "        image_path,\n",
    "        maks_type='upper'\n",
    "    )['mask']\n",
    "    upper_mask_filename = image_file.replace('.jpg', '_upper_mask.png')\n",
    "    upper_mask.save(os.path.join(upper_output_dir, upper_mask_filename))\n",
    "    print(f\"Saved upper agnostic mask to {os.path.join(upper_output_dir, upper_mask_filename)}\")\n",
    "\n",
    "    # 하의 마스크 생성 및 저장\n",
    "    lower_mask = automasker(\n",
    "        image_path,\n",
    "        maks_type='lower'\n",
    "    )['mask']\n",
    "    lower_mask_filename = image_file.replace('.jpg', '_lower_mask.png')\n",
    "    lower_mask.save(os.path.join(lower_output_dir, lower_mask_filename))\n",
    "    print(f\"Saved lower agnostic mask to {os.path.join(lower_output_dir, lower_mask_filename)}\")\n",
    "\n",
    "    # 생성된 마스크 시각화 (선택 사항)\n",
    "    upper_mask_img = PIL.Image.open(os.path.join(upper_output_dir, upper_mask_filename))\n",
    "    lower_mask_img = PIL.Image.open(os.path.join(lower_output_dir, lower_mask_filename))\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(upper_mask_img, cmap='gray')\n",
    "    plt.title(f\"Upper Mask - {image_file}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(lower_mask_img, cmap='gray')\n",
    "    plt.title(f\"Lower Mask - {image_file}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
