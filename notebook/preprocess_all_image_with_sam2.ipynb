{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. renamed\n",
    "## 2. resize_and_crop\n",
    "## 3. segment person or cloth with sam2-small\n",
    "## 4. make masked imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run this code with sam2 env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install accelerate\n",
    "# !pip install diffusers\n",
    "# !pip install onnxruntime scipy jsonschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "current_dir = os.getcwd()\n",
    "project_root_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "catvton_dir = os.path.join(project_root_dir, \"CatVTON\")\n",
    "\n",
    "if catvton_dir not in sys.path:\n",
    "    sys.path.insert(0, catvton_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'person_image_path': 'c:\\\\Users\\\\coldbrew\\\\VTON-project\\\\data\\\\renamed\\\\renamed_person_images\\\\Jonghyeon_manA_mana_120.jpg',\n",
       "  'upper_cloth_path': 'c:\\\\users\\\\coldbrew\\\\vton-project\\\\data\\\\renamed\\\\renamed_cloth_images\\\\mana00.jpg',\n",
       "  'lower_cloth_path': 'c:\\\\users\\\\coldbrew\\\\vton-project\\\\data\\\\renamed\\\\renamed_cloth_images\\\\mana01.jpg'},\n",
       " {'person_image_path': 'c:\\\\Users\\\\coldbrew\\\\VTON-project\\\\data\\\\renamed\\\\renamed_person_images\\\\Jonghyeon_manA_mana_150.jpg',\n",
       "  'upper_cloth_path': 'c:\\\\users\\\\coldbrew\\\\vton-project\\\\data\\\\renamed\\\\renamed_cloth_images\\\\mana00.jpg',\n",
       "  'lower_cloth_path': 'c:\\\\users\\\\coldbrew\\\\vton-project\\\\data\\\\renamed\\\\renamed_cloth_images\\\\mana01.jpg'},\n",
       " {'person_image_path': 'c:\\\\Users\\\\coldbrew\\\\VTON-project\\\\data\\\\renamed\\\\renamed_person_images\\\\Jonghyeon_manA_mana_30.jpg',\n",
       "  'upper_cloth_path': 'c:\\\\users\\\\coldbrew\\\\vton-project\\\\data\\\\renamed\\\\renamed_cloth_images\\\\mana00.jpg',\n",
       "  'lower_cloth_path': 'c:\\\\users\\\\coldbrew\\\\vton-project\\\\data\\\\renamed\\\\renamed_cloth_images\\\\mana01.jpg'},\n",
       " {'person_image_path': 'c:\\\\Users\\\\coldbrew\\\\VTON-project\\\\data\\\\renamed\\\\renamed_person_images\\\\Jonghyeon_manA_mana_60.jpg',\n",
       "  'upper_cloth_path': 'c:\\\\users\\\\coldbrew\\\\vton-project\\\\data\\\\renamed\\\\renamed_cloth_images\\\\mana00.jpg',\n",
       "  'lower_cloth_path': 'c:\\\\users\\\\coldbrew\\\\vton-project\\\\data\\\\renamed\\\\renamed_cloth_images\\\\mana01.jpg'},\n",
       " {'person_image_path': 'c:\\\\Users\\\\coldbrew\\\\VTON-project\\\\data\\\\renamed\\\\renamed_person_images\\\\Jonghyeon_manA_mana_90.jpg',\n",
       "  'upper_cloth_path': 'c:\\\\users\\\\coldbrew\\\\vton-project\\\\data\\\\renamed\\\\renamed_cloth_images\\\\mana00.jpg',\n",
       "  'lower_cloth_path': 'c:\\\\users\\\\coldbrew\\\\vton-project\\\\data\\\\renamed\\\\renamed_cloth_images\\\\mana01.jpg'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define source directories\n",
    "renamed_person_dir = os.path.join(project_root_dir, \"data\", \"renamed\", \"renamed_person_images\")\n",
    "renamed_cloth_dir  = os.path.join(project_root_dir, \"data\", \"renamed\", \"renamed_cloth_images\")\n",
    "\n",
    "# Define destination directories for viton-hd style dataset\n",
    "dest_person_dir = os.path.join(project_root_dir, \"data\",\"dataset\", \"image\")\n",
    "dest_cloth_upper = os.path.join(project_root_dir, \"data\",\"dataset\", \"cloth\", \"upper_img_sam2\")\n",
    "dest_cloth_lower = os.path.join(project_root_dir, \"data\",\"dataset\", \"cloth\", \"lower_img_sam2\")\n",
    "dest_mask_upper = os.path.join(project_root_dir, \"data\",\"dataset\", \"cloth\", \"upper_mask_sam2\")\n",
    "dest_mask_lower = os.path.join(project_root_dir, \"data\",\"dataset\", \"cloth\", \"lower_mask_sam2\")\n",
    "\n",
    "os.makedirs(dest_person_dir, exist_ok=True)\n",
    "os.makedirs(dest_cloth_upper, exist_ok=True)\n",
    "os.makedirs(dest_cloth_lower, exist_ok=True)\n",
    "os.makedirs(dest_mask_upper, exist_ok=True)\n",
    "os.makedirs(dest_mask_lower, exist_ok=True)\n",
    "\n",
    "# 페어 만들기\n",
    "person_cloth_pairs = {\n",
    "    \"person_image_path\" : \"\",\n",
    "    \"upper_cloth_path\" : \"\",\n",
    "    \"lower_cloth_path\" : \"\"\n",
    "}\n",
    "person_cloth_pairs_list = []\n",
    "#/Users/coldbrew/Documents/VTON-project/data/renamed/renamed_person_images/Jonghyeon_manA_mana_30.jpg\n",
    "for person_file_name in sorted(os.listdir(renamed_person_dir)):\n",
    "    person_cloth_pairs[\"person_image_path\"] = os.path.join(renamed_person_dir, person_file_name)\n",
    "    person_cloth_pairs[\"upper_cloth_path\"] = os.path.join(renamed_cloth_dir, f\"{person_file_name.split('_')[1]}00.jpg\").lower()\n",
    "    person_cloth_pairs[\"lower_cloth_path\"] = os.path.join(renamed_cloth_dir, f\"{person_file_name.split('_')[2]}01.jpg\").lower()\n",
    "    person_cloth_pairs_list.append(person_cloth_pairs.copy())\n",
    "    \n",
    "\n",
    "person_cloth_pairs_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sam2 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 마스크에서 의상 마스크 찾는 함수 만들기\n",
    "# 하나만 찾아야하고 여러개면 오류 발생\n",
    "def find_cloth_mask(cloth_image, masks):\n",
    "    img_h, img_w = cloth_image.shape[:2]\n",
    "    x_min, x_max = int(img_w * 0.4), int(img_w * 0.6)  # 이미지 가로 40~60%\n",
    "    y_min, y_max = int(img_h * 0.2), int(img_h * 0.5)  # 이미지 세로 20~50%\n",
    "\n",
    "    # 박스 안에 가장 많이 포함되는 마스크 찾기\n",
    "    best_mask = None\n",
    "    max_overlap = 0\n",
    "\n",
    "    for mask in masks:\n",
    "        x, y, w, h = mask['bbox']\n",
    "        \n",
    "        # 마스크의 좌표 (bbox)\n",
    "        mask_x_min, mask_x_max = x, x + w\n",
    "        mask_y_min, mask_y_max = y, y + h\n",
    "        \n",
    "        # 중앙 박스와의 겹치는 부분 계산\n",
    "        overlap_x_min = max(x_min, mask_x_min)\n",
    "        overlap_x_max = min(x_max, mask_x_max)\n",
    "        overlap_y_min = max(y_min, mask_y_min)\n",
    "        overlap_y_max = min(y_max, mask_y_max)\n",
    "        \n",
    "        # 겹치는 영역의 크기 계산\n",
    "        overlap_width = max(0, overlap_x_max - overlap_x_min)\n",
    "        overlap_height = max(0, overlap_y_max - overlap_y_min)\n",
    "        overlap_area = overlap_width * overlap_height\n",
    "        \n",
    "        # 가장 많이 겹치는 마스크 선택\n",
    "        if overlap_area > max_overlap:\n",
    "            best_mask = mask\n",
    "            max_overlap = overlap_area\n",
    "\n",
    "    # 마스크가 없으면 종료\n",
    "    if best_mask is None:\n",
    "        print(\"⚠️ 중앙 박스 안에 포함되는 마스크(상의/바지)를 찾을 수 없습니다.\")\n",
    "    else:\n",
    "        return best_mask['segmentation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "project_root_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sam_root = os.path.join(project_root_dir,\"sam2\")\n",
    "sys.path.insert(0, sam_root)\n",
    "\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "\n",
    "model_cfg = os.path.join(sam_root,\"checkpoints\\sam2.1_hiera_s.yaml\")\n",
    "sam2_checkpoint = os.path.join(sam_root,\"checkpoints\\sam2.1_hiera_small.pt\")\n",
    "\n",
    "sam2 = build_sam2(model_cfg, sam2_checkpoint, device=\"cuda\", apply_postprocessing=True)\n",
    "\n",
    "mask_generator = SAM2AutomaticMaskGenerator(sam2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30/195 [02:16<12:30,  4.55s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# 마스크 생성\u001b[39;00m\n\u001b[0;32m     30\u001b[0m upper_masks \u001b[38;5;241m=\u001b[39m mask_generator\u001b[38;5;241m.\u001b[39mgenerate(upper_img_rotated)\n\u001b[1;32m---> 31\u001b[0m lower_masks \u001b[38;5;241m=\u001b[39m \u001b[43mmask_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlower_img_rotated\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m segmented_upper_mask \u001b[38;5;241m=\u001b[39m find_cloth_mask(upper_img_rotated, upper_masks)\n\u001b[0;32m     33\u001b[0m segmented_lower_mask \u001b[38;5;241m=\u001b[39m find_cloth_mask(lower_img_rotated, lower_masks)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\sam2\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\coldbrew\\VTON-project\\sam2\\sam2\\automatic_mask_generator.py:196\u001b[0m, in \u001b[0;36mSAM2AutomaticMaskGenerator.generate\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;124;03mGenerates masks for the given image.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m         the mask, given in XYWH format.\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# Generate masks\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m mask_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# Encode masks\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoco_rle\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\coldbrew\\VTON-project\\sam2\\sam2\\automatic_mask_generator.py:233\u001b[0m, in \u001b[0;36mSAM2AutomaticMaskGenerator._generate_masks\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    231\u001b[0m data \u001b[38;5;241m=\u001b[39m MaskData()\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m crop_box, layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(crop_boxes, layer_idxs):\n\u001b[1;32m--> 233\u001b[0m     crop_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_crop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop_box\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m     data\u001b[38;5;241m.\u001b[39mcat(crop_data)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# Remove duplicate masks between crops\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\coldbrew\\VTON-project\\sam2\\sam2\\automatic_mask_generator.py:271\u001b[0m, in \u001b[0;36mSAM2AutomaticMaskGenerator._process_crop\u001b[1;34m(self, image, crop_box, crop_layer_idx, orig_size)\u001b[0m\n\u001b[0;32m    269\u001b[0m data \u001b[38;5;241m=\u001b[39m MaskData()\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (points,) \u001b[38;5;129;01min\u001b[39;00m batch_iterator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoints_per_batch, points_for_image):\n\u001b[1;32m--> 271\u001b[0m     batch_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcropped_im_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop_box\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m     data\u001b[38;5;241m.\u001b[39mcat(batch_data)\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m batch_data\n",
      "File \u001b[1;32mc:\\Users\\coldbrew\\VTON-project\\sam2\\sam2\\automatic_mask_generator.py:334\u001b[0m, in \u001b[0;36mSAM2AutomaticMaskGenerator._process_batch\u001b[1;34m(self, points, im_size, crop_box, orig_size, normalize)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_iou_thresh \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m    333\u001b[0m     keep_mask \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miou_preds\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_iou_thresh\n\u001b[1;32m--> 334\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeep_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;66;03m# Calculate and filter by stability score\u001b[39;00m\n\u001b[0;32m    337\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstability_score\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m calculate_stability_score(\n\u001b[0;32m    338\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmasks\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_threshold, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstability_score_offset\n\u001b[0;32m    339\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\coldbrew\\VTON-project\\sam2\\sam2\\utils\\amg.py:51\u001b[0m, in \u001b[0;36mMaskData.filter\u001b[1;34m(self, keep)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stats[k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stats[k] \u001b[38;5;241m=\u001b[39m v[torch\u001b[38;5;241m.\u001b[39mas_tensor(keep, device\u001b[38;5;241m=\u001b[39mv\u001b[38;5;241m.\u001b[39mdevice)]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stats[k] \u001b[38;5;241m=\u001b[39m v[keep\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from utils import resize_and_crop, resize_and_padding\n",
    "from tqdm import tqdm\n",
    "import rembg\n",
    "import PIL\n",
    "import numpy as np\n",
    "\n",
    "for idx, pcp_dict in tqdm(enumerate(person_cloth_pairs_list), total=len(person_cloth_pairs_list)):\n",
    "    new_name = f\"{idx:05d}.jpg\"\n",
    "    # 파일 열기\n",
    "    person_img = PIL.Image.open(pcp_dict[\"person_image_path\"]).convert(\"RGB\")\n",
    "    upper_img = PIL.Image.open(pcp_dict[\"upper_cloth_path\"]).convert(\"RGB\")\n",
    "    lower_img = PIL.Image.open(pcp_dict[\"lower_cloth_path\"]).convert(\"RGB\")\n",
    "\n",
    "    # 사람 이미지는 resize_and_crop 함수로, 옷 이미지는 resize_and_padding 함수로 크기 조정\n",
    "    person_img = resize_and_crop(person_img, (1024, 768))\n",
    "    upper_img = resize_and_crop(upper_img, (1024, 768))\n",
    "    lower_img = resize_and_crop(lower_img, (1024, 768))\n",
    "\n",
    "    # 파일 회전\n",
    "    person_img_rotated = person_img.rotate(0, expand=True)\n",
    "    upper_img_rotated = upper_img.rotate(270, expand=True)\n",
    "    lower_img_rotated = lower_img.rotate(270, expand=True)\n",
    "    \n",
    "    # to numpy\n",
    "    # person_img_rotated = np.array(person_img_rotated)\n",
    "    upper_img_rotated = np.array(upper_img_rotated)\n",
    "    lower_img_rotated = np.array(lower_img_rotated)\n",
    "\n",
    "    # 마스크 생성\n",
    "    upper_masks = mask_generator.generate(upper_img_rotated)\n",
    "    lower_masks = mask_generator.generate(lower_img_rotated)\n",
    "    segmented_upper_mask = find_cloth_mask(upper_img_rotated, upper_masks)\n",
    "    segmented_lower_mask = find_cloth_mask(lower_img_rotated, lower_masks)\n",
    "    \n",
    "    # numpy 배열로 변환 (segmentation 연산을 위해)\n",
    "    upper_img_np = np.array(upper_img_rotated)\n",
    "    lower_img_np = np.array(lower_img_rotated)\n",
    "\n",
    "    # --- 3. 출력 이미지 생성 ---\n",
    "    # (a) 옷 영역은 원본, 나머지 영역은 흰색 처리 (cloth extracted image)\n",
    "    # segmented_upper_mask[..., None]를 사용해 채널 차원을 맞춰줍니다.\n",
    "    upper_cloth_extracted_np = np.where(segmented_upper_mask[..., None], upper_img_np, 255)\n",
    "    lower_cloth_extracted_np = np.where(segmented_lower_mask[..., None], lower_img_np, 255)\n",
    "    upper_cloth_extracted_img = PIL.Image.fromarray(upper_cloth_extracted_np.astype(np.uint8))\n",
    "    lower_cloth_extracted_img = PIL.Image.fromarray(lower_cloth_extracted_np.astype(np.uint8))\n",
    "    \n",
    "    # (b) 바이너리 마스크 이미지: 옷 영역은 흰색(255), 배경은 검정(0)\n",
    "    upper_binary_mask_np = (segmented_upper_mask.astype(np.uint8)) * 255\n",
    "    lower_binary_mask_np = (segmented_lower_mask.astype(np.uint8)) * 255\n",
    "    upper_binary_mask_img = PIL.Image.fromarray(upper_binary_mask_np, mode=\"L\")\n",
    "    lower_binary_mask_img = PIL.Image.fromarray(lower_binary_mask_np, mode=\"L\")\n",
    "\n",
    "    # --- 4. 저장 ---\n",
    "    upper_cloth_extracted_img.save(os.path.join(dest_cloth_upper, new_name))\n",
    "    lower_cloth_extracted_img.save(os.path.join(dest_cloth_lower, new_name))\n",
    "    upper_binary_mask_img.save(os.path.join(dest_mask_upper, new_name))\n",
    "    lower_binary_mask_img.save(os.path.join(dest_mask_lower, new_name))\n",
    "\n",
    "    # # 흰 배경 생성\n",
    "    # person_white_bg = PIL.Image.new(\"RGB\", (768, 1024), (255, 255, 255))\n",
    "    # upper_white_bg = PIL.Image.new(\"RGB\", (768, 1024), (255, 255, 255))\n",
    "    # lower_white_bg = PIL.Image.new(\"RGB\", (768, 1024), (255, 255, 255))\n",
    "\n",
    "    # person_white_bg.paste(person_img, (0, 0), person_img)\n",
    "    # upper_white_bg.paste(segmented_upper_mask, (0, 0), segmented_upper_mask)\n",
    "    # lower_white_bg.paste(segmented_lower_mask, (0, 0), segmented_lower_mask)\n",
    "\n",
    "    # # 파일 저장\n",
    "    # person_white_bg.save(os.path.join(dest_person_dir, new_name))\n",
    "    # upper_white_bg.save(os.path.join(dest_cloth_upper, new_name))\n",
    "    # lower_white_bg.save(os.path.join(dest_cloth_lower, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
